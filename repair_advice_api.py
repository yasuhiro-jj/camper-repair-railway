#!/usr/bin/env python3
"""
ä¿®ç†ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚»ãƒ³ã‚¿ãƒ¼ç”¨ã®APIã‚µãƒ¼ãƒãƒ¼
RAGã‚·ã‚¹ãƒ†ãƒ ã€Notionãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
"""

from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import os
import json
from typing import Dict, List, Any
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# æ‹¡å¼µRAGã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from enhanced_rag_system import create_enhanced_rag_system, enhanced_rag_retrieve
    RAG_AVAILABLE = True
except ImportError as e:
    print(f"Warning: RAGã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {e}")
    RAG_AVAILABLE = False

# Notionã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from notion_client import Client
    NOTION_AVAILABLE = True
except ImportError:
    print("Warning: Notionã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    NOTION_AVAILABLE = False

app = Flask(__name__)
CORS(app)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
rag_db = None
notion_client = None

def initialize_rag_system():
    """RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
    global rag_db
    if RAG_AVAILABLE and not rag_db:
        try:
            # OpenAI APIã‚­ãƒ¼ã®ç¢ºèª
            openai_api_key = os.getenv("OPENAI_API_KEY")
            if not openai_api_key or openai_api_key == "your_openai_api_key_here":
                print("âš ï¸ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚RAGã‚·ã‚¹ãƒ†ãƒ ã¯ç„¡åŠ¹ã§ã™ã€‚")
                rag_db = None
                return
            
            rag_db = create_enhanced_rag_system()
            print("âœ… RAGã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ")
        except Exception as e:
            print(f"âŒ RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
            rag_db = None

def initialize_notion_client():
    """Notionã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–"""
    global notion_client
    if NOTION_AVAILABLE and not notion_client:
        try:
            api_key = os.getenv("NOTION_API_KEY")
            if api_key:
                notion_client = Client(auth=api_key)
                print("âœ… Notionã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¾ã—ãŸ")
            else:
                print("âŒ NOTION_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        except Exception as e:
            print(f"âŒ Notionã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
            notion_client = None

def search_notion_repair_cases(query: str) -> List[Dict]:
    """Notionã‹ã‚‰ä¿®ç†ã‚±ãƒ¼ã‚¹ã‚’æ¤œç´¢"""
    if not notion_client:
        return []
    
    try:
        case_db_id = os.getenv("CASE_DB_ID")
        if not case_db_id:
            return []
        
        # Notionã‹ã‚‰ä¿®ç†ã‚±ãƒ¼ã‚¹ã‚’å–å¾—
        response = notion_client.databases.query(
            database_id=case_db_id,
            filter={
                "or": [
                    {
                        "property": "ç—‡çŠ¶",
                        "rich_text": {
                            "contains": query
                        }
                    },
                    {
                        "property": "åŸå› ",
                        "rich_text": {
                            "contains": query
                        }
                    },
                    {
                        "property": "è§£æ±ºç­–",
                        "rich_text": {
                            "contains": query
                        }
                    }
                ]
            }
        )
        
        cases = response.get("results", [])
        repair_cases = []
        
        for case in cases:
            properties = case.get("properties", {})
            
            # ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã®å–å¾—
            symptoms = get_notion_text(properties.get("ç—‡çŠ¶", {}))
            causes = get_notion_text(properties.get("åŸå› ", {}))
            solutions = get_notion_text(properties.get("è§£æ±ºç­–", {}))
            costs = get_notion_text(properties.get("è²»ç”¨ç›®å®‰", {}))
            tools = get_notion_text(properties.get("å¿…è¦ãªå·¥å…·", {}))
            parts = get_notion_text(properties.get("å¿…è¦ãªéƒ¨å“", {}))
            
            repair_case = {
                "id": case["id"],
                "symptoms": symptoms,
                "causes": causes,
                "solutions": solutions,
                "costs": costs,
                "tools": tools,
                "parts": parts,
                "source": "notion"
            }
            repair_cases.append(repair_case)
        
        return repair_cases
        
    except Exception as e:
        print(f"âŒ Notionæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def get_notion_text(property_obj):
    """Notionãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—"""
    if not property_obj:
        return ""
    
    if property_obj.get("type") == "rich_text":
        rich_text = property_obj.get("rich_text", [])
        return "".join([text.get("plain_text", "") for text in rich_text])
    elif property_obj.get("type") == "title":
        title = property_obj.get("title", [])
        return "".join([text.get("plain_text", "") for text in title])
    elif property_obj.get("type") == "select":
        select = property_obj.get("select")
        return select.get("name", "") if select else ""
    elif property_obj.get("type") == "multi_select":
        multi_select = property_obj.get("multi_select", [])
        return ", ".join([item.get("name", "") for item in multi_select])
    
    return ""

def search_text_files(query: str) -> List[Dict]:
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é–¢é€£æƒ…å ±ã‚’æ¤œç´¢ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    results = []
    
    # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
    txt_files = [
        "ãƒãƒƒãƒ†ãƒªãƒ¼.txt", "ã‚µãƒ–ãƒãƒƒãƒ†ãƒªãƒ¼è©³ç´°.txt", "ãƒˆã‚¤ãƒ¬.txt", 
        "é›¨æ¼ã‚Š.txt", "ã‚¨ã‚¢ã‚³ãƒ³.txt", "å†·è”µåº«.txt", "ã‚¬ã‚¹ã‚³ãƒ³ãƒ­.txt",
        "ã‚½ãƒ¼ãƒ©ãƒ¼ãƒ‘ãƒãƒ«.txt", "ã‚¤ãƒ³ãƒãƒ¼ã‚¿ãƒ¼.txt", "é›»è£…ç³».txt",
        "FFãƒ’ãƒ¼ã‚¿ãƒ¼.txt", "ã‚¦ã‚¤ãƒ³ãƒ‰ã‚¦.txt", "ãƒ‰ã‚¢ãƒ»çª“ã®é–‹é–‰ä¸è‰¯.txt",
        "ãƒ’ãƒ¥ãƒ¼ã‚ºåˆ‡ã‚Œãƒ»ãƒªãƒ¬ãƒ¼ä¸è‰¯.txt", "ãƒ™ãƒ³ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ä»˜ããƒˆã‚¤ãƒ¬ãƒ•ã‚¡ãƒ³ã®æ•…éšœ.txt",
        "ãƒ«ãƒ¼ãƒ•ãƒ™ãƒ³ãƒˆã€€æ›æ°—æ‰‡.txt", "å¤–éƒ¨é›»æº.txt", "å®¤å†…LED.txt",
        "å®¶å…·.txt", "æ’æ°´ã‚¿ãƒ³ã‚¯.txt", "æ°´é“ãƒãƒ³ãƒ—.txt", "ç•°éŸ³.txt",
        "è»Šä½“å¤–è£…ã®ç ´æ.txt", "ã‚­ãƒ£ãƒ³ãƒ”ãƒ³ã‚°ã‚«ãƒ¼ã€€ã‚¿ã‚¤ãƒ¤ã€€.txt"
    ]
    
    # ã‚¯ã‚¨ãƒªã®é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆæ‹¡å¼µç‰ˆï¼‰
    query_lower = query.lower()
    related_keywords = []
    
    # ã‚ˆã‚ŠåŒ…æ‹¬çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°
    keyword_mappings = {
        # ãƒãƒƒãƒ†ãƒªãƒ¼é–¢é€£
        "ãƒãƒƒãƒ†ãƒªãƒ¼": ["ãƒãƒƒãƒ†ãƒªãƒ¼", "å……é›»", "é›»åœ§", "ä¸ŠãŒã‚Š", "å§‹å‹•", "ã‚¨ãƒ³ã‚¸ãƒ³", "é›»æº", "é›»åŠ›", "æ”¾é›»"],
        "å……é›»": ["ãƒãƒƒãƒ†ãƒªãƒ¼", "å……é›»", "é›»åœ§", "ä¸ŠãŒã‚Š", "å§‹å‹•", "ã‚¨ãƒ³ã‚¸ãƒ³", "é›»æº", "é›»åŠ›", "æ”¾é›»"],
        "é›»åœ§": ["ãƒãƒƒãƒ†ãƒªãƒ¼", "å……é›»", "é›»åœ§", "ä¸ŠãŒã‚Š", "å§‹å‹•", "ã‚¨ãƒ³ã‚¸ãƒ³", "é›»æº", "é›»åŠ›", "æ”¾é›»"],
        "å§‹å‹•": ["ãƒãƒƒãƒ†ãƒªãƒ¼", "å……é›»", "é›»åœ§", "ä¸ŠãŒã‚Š", "å§‹å‹•", "ã‚¨ãƒ³ã‚¸ãƒ³", "é›»æº", "é›»åŠ›", "æ”¾é›»"],
        
        # ãƒˆã‚¤ãƒ¬é–¢é€£
        "ãƒˆã‚¤ãƒ¬": ["ãƒˆã‚¤ãƒ¬", "æ°´", "æµã‚Œ", "ãƒãƒ³ãƒ—", "ã‚«ã‚»ãƒƒãƒˆ", "æ’æ°´", "æ°´æ¼ã‚Œ"],
        "æ°´": ["ãƒˆã‚¤ãƒ¬", "æ°´", "æµã‚Œ", "ãƒãƒ³ãƒ—", "ã‚«ã‚»ãƒƒãƒˆ", "æ’æ°´", "æ°´æ¼ã‚Œ", "æ°´é“"],
        "ãƒãƒ³ãƒ—": ["ãƒˆã‚¤ãƒ¬", "æ°´", "æµã‚Œ", "ãƒãƒ³ãƒ—", "ã‚«ã‚»ãƒƒãƒˆ", "æ’æ°´", "æ°´æ¼ã‚Œ", "æ°´é“"],
        
        # ã‚¨ã‚¢ã‚³ãƒ³é–¢é€£
        "ã‚¨ã‚¢ã‚³ãƒ³": ["ã‚¨ã‚¢ã‚³ãƒ³", "å†·æˆ¿", "æš–æˆ¿", "å†·ãˆãªã„", "ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼", "ç©ºèª¿", "æ¸©åº¦"],
        "å†·æˆ¿": ["ã‚¨ã‚¢ã‚³ãƒ³", "å†·æˆ¿", "æš–æˆ¿", "å†·ãˆãªã„", "ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼", "ç©ºèª¿", "æ¸©åº¦"],
        "æš–æˆ¿": ["ã‚¨ã‚¢ã‚³ãƒ³", "å†·æˆ¿", "æš–æˆ¿", "å†·ãˆãªã„", "ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼", "ç©ºèª¿", "æ¸©åº¦", "ãƒ’ãƒ¼ã‚¿ãƒ¼"],
        
        # é›¨æ¼ã‚Šé–¢é€£
        "é›¨æ¼ã‚Š": ["é›¨æ¼ã‚Š", "æ°´æ¼ã‚Œ", "ã‚·ãƒ¼ãƒªãƒ³ã‚°", "é˜²æ°´", "å±‹æ ¹", "å¤©äº•"],
        "æ°´æ¼ã‚Œ": ["é›¨æ¼ã‚Š", "æ°´æ¼ã‚Œ", "ã‚·ãƒ¼ãƒªãƒ³ã‚°", "é˜²æ°´", "å±‹æ ¹", "å¤©äº•"],
        
        # é›»è£…ç³»é–¢é€£
        "é›»è£…": ["é›»è£…", "é›»æ°—", "é…ç·š", "ãƒ’ãƒ¥ãƒ¼ã‚º", "ãƒªãƒ¬ãƒ¼", "ã‚¹ã‚¤ãƒƒãƒ", "ã‚³ãƒ³ã‚»ãƒ³ãƒˆ"],
        "ãƒ’ãƒ¥ãƒ¼ã‚º": ["é›»è£…", "é›»æ°—", "é…ç·š", "ãƒ’ãƒ¥ãƒ¼ã‚º", "ãƒªãƒ¬ãƒ¼", "ã‚¹ã‚¤ãƒƒãƒ", "ã‚³ãƒ³ã‚»ãƒ³ãƒˆ"],
        "é…ç·š": ["é›»è£…", "é›»æ°—", "é…ç·š", "ãƒ’ãƒ¥ãƒ¼ã‚º", "ãƒªãƒ¬ãƒ¼", "ã‚¹ã‚¤ãƒƒãƒ", "ã‚³ãƒ³ã‚»ãƒ³ãƒˆ"],
        
        # ã‚¿ã‚¤ãƒ¤é–¢é€£
        "ã‚¿ã‚¤ãƒ¤": ["ã‚¿ã‚¤ãƒ¤", "ãƒ›ã‚¤ãƒ¼ãƒ«", "ãƒ‘ãƒ³ã‚¯", "ç©ºæ°—åœ§", "äº¤æ›", "æ‘©è€—"],
        "ãƒ‘ãƒ³ã‚¯": ["ã‚¿ã‚¤ãƒ¤", "ãƒ›ã‚¤ãƒ¼ãƒ«", "ãƒ‘ãƒ³ã‚¯", "ç©ºæ°—åœ§", "äº¤æ›", "æ‘©è€—"],
        
        # ãƒ‰ã‚¢ãƒ»çª“é–¢é€£
        "ãƒ‰ã‚¢": ["ãƒ‰ã‚¢", "çª“", "é–‹é–‰", "é–‰ã¾ã‚‰ãªã„", "é–‹ã‹ãªã„", "éµ", "ãƒ­ãƒƒã‚¯"],
        "çª“": ["ãƒ‰ã‚¢", "çª“", "é–‹é–‰", "é–‰ã¾ã‚‰ãªã„", "é–‹ã‹ãªã„", "éµ", "ãƒ­ãƒƒã‚¯"],
        
        # å†·è”µåº«é–¢é€£
        "å†·è”µåº«": ["å†·è”µåº«", "å†·å‡", "å†·å´", "æ¸©åº¦", "é›»æº", "ãƒ¢ãƒ¼ã‚¿ãƒ¼"],
        "å†·å‡": ["å†·è”µåº«", "å†·å‡", "å†·å´", "æ¸©åº¦", "é›»æº", "ãƒ¢ãƒ¼ã‚¿ãƒ¼"],
        
        # ã‚¬ã‚¹ã‚³ãƒ³ãƒ­é–¢é€£
        "ã‚¬ã‚¹": ["ã‚¬ã‚¹", "ã‚³ãƒ³ãƒ­", "ç«", "ç‚¹ç«", "ãƒãƒ¼ãƒŠãƒ¼", "ã‚¬ã‚¹æ¼ã‚Œ"],
        "ã‚³ãƒ³ãƒ­": ["ã‚¬ã‚¹", "ã‚³ãƒ³ãƒ­", "ç«", "ç‚¹ç«", "ãƒãƒ¼ãƒŠãƒ¼", "ã‚¬ã‚¹æ¼ã‚Œ"],
        
        # ã‚½ãƒ¼ãƒ©ãƒ¼ãƒ‘ãƒãƒ«é–¢é€£
        "ã‚½ãƒ¼ãƒ©ãƒ¼": ["ã‚½ãƒ¼ãƒ©ãƒ¼", "ãƒ‘ãƒãƒ«", "å¤ªé™½å…‰", "ç™ºé›»", "å……é›»", "ãƒãƒƒãƒ†ãƒªãƒ¼"],
        "ãƒ‘ãƒãƒ«": ["ã‚½ãƒ¼ãƒ©ãƒ¼", "ãƒ‘ãƒãƒ«", "å¤ªé™½å…‰", "ç™ºé›»", "å……é›»", "ãƒãƒƒãƒ†ãƒªãƒ¼"],
        
        # ã‚¤ãƒ³ãƒãƒ¼ã‚¿ãƒ¼é–¢é€£
        "ã‚¤ãƒ³ãƒãƒ¼ã‚¿ãƒ¼": ["ã‚¤ãƒ³ãƒãƒ¼ã‚¿ãƒ¼", "å¤‰æ›", "AC", "DC", "é›»æº", "å‡ºåŠ›"],
        
        # ãƒ’ãƒ¼ã‚¿ãƒ¼é–¢é€£
        "ãƒ’ãƒ¼ã‚¿ãƒ¼": ["ãƒ’ãƒ¼ã‚¿ãƒ¼", "æš–æˆ¿", "FF", "æš–ã‹ããªã„", "æ¸©åº¦", "æš–æˆ¿"],
        "æš–æˆ¿": ["ãƒ’ãƒ¼ã‚¿ãƒ¼", "æš–æˆ¿", "FF", "æš–ã‹ããªã„", "æ¸©åº¦", "æš–æˆ¿"],
        
        # æ›æ°—é–¢é€£
        "æ›æ°—": ["æ›æ°—", "ãƒ•ã‚¡ãƒ³", "ãƒ™ãƒ³ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼", "ãƒ«ãƒ¼ãƒ•ãƒ™ãƒ³ãƒˆ", "ç©ºæ°—", "é¢¨"],
        "ãƒ•ã‚¡ãƒ³": ["æ›æ°—", "ãƒ•ã‚¡ãƒ³", "ãƒ™ãƒ³ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼", "ãƒ«ãƒ¼ãƒ•ãƒ™ãƒ³ãƒˆ", "ç©ºæ°—", "é¢¨"],
        
        # ç…§æ˜é–¢é€£
        "ç…§æ˜": ["ç…§æ˜", "LED", "ãƒ©ã‚¤ãƒˆ", "æ˜ã‹ã‚Š", "é›»çƒ", "ç‚¹ç¯"],
        "LED": ["ç…§æ˜", "LED", "ãƒ©ã‚¤ãƒˆ", "æ˜ã‹ã‚Š", "é›»çƒ", "ç‚¹ç¯"],
        
        # å®¶å…·é–¢é€£
        "å®¶å…·": ["å®¶å…·", "ãƒ†ãƒ¼ãƒ–ãƒ«", "æ¤…å­", "ãƒ™ãƒƒãƒ‰", "åç´", "å›ºå®š"],
        
        # ç•°éŸ³é–¢é€£
        "ç•°éŸ³": ["ç•°éŸ³", "éŸ³", "ã†ã‚‹ã•ã„", "æŒ¯å‹•", "ã‚¬ã‚¿ã‚¬ã‚¿", "ã‚­ãƒ¼ã‚­ãƒ¼"],
        "éŸ³": ["ç•°éŸ³", "éŸ³", "ã†ã‚‹ã•ã„", "æŒ¯å‹•", "ã‚¬ã‚¿ã‚¬ã‚¿", "ã‚­ãƒ¼ã‚­ãƒ¼"],
        
        # å¤–è£…é–¢é€£
        "å¤–è£…": ["å¤–è£…", "ãƒœãƒ‡ã‚£", "å‚·", "ç ´æ", "éŒ†", "å¡—è£…"],
        "ãƒœãƒ‡ã‚£": ["å¤–è£…", "ãƒœãƒ‡ã‚£", "å‚·", "ç ´æ", "éŒ†", "å¡—è£…"]
    }
    
    # ã‚¯ã‚¨ãƒªã‹ã‚‰é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    for word in query_lower.split():
        if word in keyword_mappings:
            related_keywords.extend(keyword_mappings[word])
    
    # é‡è¤‡ã‚’é™¤å»
    related_keywords = list(set(related_keywords))
    
    print(f"ğŸ” æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {query}")
    print(f"ğŸ”— é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {related_keywords}")
    
    for filename in txt_files:
        if os.path.exists(filename):
            try:
                with open(filename, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                content_lower = content.lower()
                is_relevant = False
                match_type = ""
                
                # ç›´æ¥çš„ãªãƒãƒƒãƒ
                if query_lower in content_lower:
                    is_relevant = True
                    match_type = "direct"
                
                # é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ã®ãƒãƒƒãƒ
                if not is_relevant and related_keywords:
                    for keyword in related_keywords:
                        if keyword.lower() in content_lower:
                            is_relevant = True
                            match_type = "related"
                            break
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åã§ã®ãƒãƒƒãƒ
                if not is_relevant:
                    filename_lower = filename.lower()
                    for keyword in related_keywords:
                        if keyword.lower() in filename_lower:
                            is_relevant = True
                            match_type = "filename"
                            break
                
                # éƒ¨åˆ†ãƒãƒƒãƒãƒ³ã‚°ï¼ˆã‚ˆã‚ŠæŸ”è»Ÿãªæ¤œç´¢ï¼‰
                if not is_relevant:
                    query_words = query_lower.split()
                    for word in query_words:
                        if len(word) > 2 and word in content_lower:
                            is_relevant = True
                            match_type = "partial"
                            break
                
                if is_relevant:
                    # é–¢é€£ã™ã‚‹éƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰
                    lines = content.split('\n')
                    relevant_lines = []
                    
                    # ã‚¯ã‚¨ãƒªãŒå«ã¾ã‚Œã‚‹è¡Œã‚’æ¢ã™
                    for i, line in enumerate(lines):
                        line_lower = line.lower()
                        if (query_lower in line_lower or 
                            any(keyword.lower() in line_lower for keyword in related_keywords)):
                            # å‰å¾Œã®è¡Œã‚‚å«ã‚ã‚‹
                            start = max(0, i - 3)
                            end = min(len(lines), i + 4)
                            relevant_lines.extend(lines[start:end])
                    
                    # é‡è¤‡ã‚’é™¤å»
                    relevant_lines = list(dict.fromkeys(relevant_lines))
                    
                    if relevant_lines:
                        results.append({
                            "filename": filename,
                            "content": '\n'.join(relevant_lines[:20]),  # æœ€å¤§20è¡Œ
                            "source": "text_file",
                            "relevance": "high" if match_type == "direct" else "medium",
                            "match_type": match_type
                        })
                        print(f"âœ… ãƒãƒƒãƒç™ºè¦‹ ({filename}): {match_type}")
                        
            except Exception as e:
                print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({filename}): {e}")
    
    print(f"ğŸ“Š æ¤œç´¢çµæœ: {len(results)}ä»¶")
    return results

def extract_repair_costs_from_content(content: str) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä¿®ç†è²»ç”¨ã‚’æŠ½å‡º"""
    lines = content.split('\n')
    costs = []
    in_cost_section = False
    
    print(f"ğŸ” ä¿®ç†è²»ç”¨æŠ½å‡ºé–‹å§‹: {len(lines)}è¡Œ")
    
    for line in lines:
        line = line.strip()
        
        # ä¿®ç†è²»ç”¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®é–‹å§‹ã‚’æ¤œå‡º
        if '## ä¿®ç†è²»ç”¨ç›®å®‰' in line or 'ä¿®ç†è²»ç”¨ç›®å®‰' in line:
            in_cost_section = True
            print(f"âœ… ä¿®ç†è²»ç”¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³é–‹å§‹: {line}")
            continue
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³çµ‚äº†ã®æ¤œå‡º
        if in_cost_section and line.startswith('##') and 'ä¿®ç†è²»ç”¨ç›®å®‰' not in line:
            print(f"ğŸ”š ä¿®ç†è²»ç”¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³çµ‚äº†: {line}")
            break
        
        # ä¿®ç†è²»ç”¨é …ç›®ã®æŠ½å‡º
        if in_cost_section and line.startswith('**') and 'å††' in line:
            print(f"ğŸ’° ä¿®ç†è²»ç”¨é …ç›®ç™ºè¦‹: {line}")
            # **é …ç›®å**: é‡‘é¡ ã®å½¢å¼ã‹ã‚‰é …ç›®åã¨é‡‘é¡ã‚’æŠ½å‡º
            if '**:' in line:
                parts = line.split('**:')
                if len(parts) == 2:
                    item_name = parts[0].replace('**', '').strip()
                    cost_range = parts[1].strip()
                    cost_item = f"â€¢ {item_name}: {cost_range}"
                    costs.append(cost_item)
                    print(f"âœ… æŠ½å‡ºå®Œäº†: {cost_item}")
            # ãã®ä»–ã®å½¢å¼ã‚‚å¯¾å¿œ
            elif '**' in line and 'å††' in line:
                # **é …ç›®å** é‡‘é¡ ã®å½¢å¼
                line_clean = line.replace('**', '').strip()
                if 'å††' in line_clean:
                    cost_item = f"â€¢ {line_clean}"
                    costs.append(cost_item)
                    print(f"âœ… æŠ½å‡ºå®Œäº†: {cost_item}")
        
        # ã‚¨ã‚¢ã‚³ãƒ³.txtã®å½¢å¼ã«å¯¾å¿œï¼šç©ºè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã®é …ç›®ã‚’æ¢ã™
        if in_cost_section and not line and len(costs) > 0:
            continue
    
    print(f"ğŸ“Š æŠ½å‡ºçµæœ: {len(costs)}ä»¶")
    if costs:
        result = '\n'.join(costs)
        print(f"ğŸ“‹ æœ€çµ‚çµæœ:\n{result}")
        return result
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šä¿®ç†è²»ç”¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã§ã‚‚ã€è²»ç”¨æƒ…å ±ã‚’æ¢ã™
    print("ğŸ” ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢ã‚’é–‹å§‹...")
    for line in lines:
        line = line.strip()
        if 'å††' in line and any(keyword in line for keyword in ['äº¤æ›', 'ä¿®ç†', 'è£œå……', 'æ¸…æƒ', 'é™¤å»', 'å†æ•´å‚™']):
            print(f"ğŸ’° ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é …ç›®ç™ºè¦‹: {line}")
            if line.startswith('**') and '**:' in line:
                parts = line.split('**:')
                if len(parts) == 2:
                    item_name = parts[0].replace('**', '').strip()
                    cost_range = parts[1].strip()
                    cost_item = f"â€¢ {item_name}: {cost_range}"
                    costs.append(cost_item)
            elif line.startswith('**') and 'å††' in line:
                line_clean = line.replace('**', '').strip()
                cost_item = f"â€¢ {line_clean}"
                costs.append(cost_item)
    
    if costs:
        result = '\n'.join(costs)
        print(f"ğŸ“‹ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯çµæœ:\n{result}")
        return result
    
    return ""

def extract_repair_steps_from_content(content: str) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä¿®ç†æ‰‹é †ã‚’æŠ½å‡º"""
    import re
    
    print(f"ğŸ”§ ä¿®ç†æ‰‹é †æŠ½å‡ºé–‹å§‹")
    
    # ä¿®ç†æ‰‹é †ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¤œç´¢ï¼ˆè¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™ï¼‰
    patterns = [
        r'## ä¿®ç†æ‰‹é †\s*\n(.*?)(?=\n##|\nâš ï¸|\n\*\*|$)',
        r'ä¿®ç†æ‰‹é †\s*\n(.*?)(?=\n##|\nâš ï¸|\n\*\*|$)',
        r'## ä¿®ç†æ‰‹é †(.*?)(?=\n##|\nâš ï¸|\n\*\*|$)',
        r'ä¿®ç†æ‰‹é †(.*?)(?=\n##|\nâš ï¸|\n\*\*|$)',
        r'æ‰‹é †\s*\n(.*?)(?=\n##|\nâš ï¸|\n\*\*|$)',
        r'## æ‰‹é †\s*\n(.*?)(?=\n##|\nâš ï¸|\n\*\*|$)',
        r'è©³ç´°ä¿®ç†æ‰‹é †\s*\n(.*?)(?=\n##|\nâš ï¸|\n\*\*|$)',
        r'## è©³ç´°ä¿®ç†æ‰‹é †\s*\n(.*?)(?=\n##|\nâš ï¸|\n\*\*|$)'
    ]
    
    for i, pattern in enumerate(patterns):
        print(f"  ãƒ‘ã‚¿ãƒ¼ãƒ³ {i+1} ã‚’è©¦è¡Œä¸­...")
        steps_match = re.search(pattern, content, re.DOTALL)
        if steps_match:
            print(f"  âœ… ãƒ‘ã‚¿ãƒ¼ãƒ³ {i+1} ã§ãƒãƒƒãƒã—ã¾ã—ãŸ")
            steps_section = steps_match.group(1).strip()
            print(f"  æŠ½å‡ºã•ã‚ŒãŸã‚»ã‚¯ã‚·ãƒ§ãƒ³: {steps_section[:200]}...")
            
            # æ‰‹é †æƒ…å ±ã‚’æ•´ç†
            steps_lines = [line.strip() for line in steps_section.split('\n') if line.strip()]
            print(f"  æ‰‹é †è¡Œæ•°: {len(steps_lines)}")
            
            if steps_lines:
                result = '\n'.join(steps_lines)
                print(f"  âœ… ä¿®ç†æ‰‹é †æŠ½å‡ºæˆåŠŸ: {result[:100]}...")
                return result
            else:
                print(f"  âŒ æ‰‹é †è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        else:
            print(f"  âŒ ãƒ‘ã‚¿ãƒ¼ãƒ³ {i+1} ã§ãƒãƒƒãƒã—ã¾ã›ã‚“ã§ã—ãŸ")
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç•ªå·ä»˜ããƒªã‚¹ãƒˆã‚„ç®‡æ¡æ›¸ãã‚’æ¤œç´¢
    print(f"  ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢ã‚’å®Ÿè¡Œ...")
    all_lines = content.split('\n')
    steps_lines = []
    
    for line in all_lines:
        line = line.strip()
        # ç•ªå·ä»˜ããƒªã‚¹ãƒˆï¼ˆ1. 2. 3. ãªã©ï¼‰
        if re.match(r'^\d+\.', line):
            steps_lines.append(line)
        # ç®‡æ¡æ›¸ãï¼ˆâ€¢ - * ãªã©ï¼‰
        elif re.match(r'^[â€¢\-\*]\s', line):
            steps_lines.append(line)
        # ã€Œæ‰‹é †ã€ã€Œã‚¹ãƒ†ãƒƒãƒ—ã€ã‚’å«ã‚€è¡Œ
        elif 'æ‰‹é †' in line or 'ã‚¹ãƒ†ãƒƒãƒ—' in line:
            steps_lines.append(line)
    
    if steps_lines:
        print(f"  âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ {len(steps_lines)} è¡Œã®æ‰‹é †æƒ…å ±ã‚’ç™ºè¦‹")
        result = '\n'.join(steps_lines)
        print(f"  çµæœ: {result[:100]}...")
        return result
    
    print(f"  âŒ ä¿®ç†æ‰‹é †ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    return ""

def extract_warnings_from_content(content: str) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ³¨æ„äº‹é …ã‚’æŠ½å‡º"""
    import re
    
    print(f"âš ï¸ æ³¨æ„äº‹é …æŠ½å‡ºé–‹å§‹")
    
    # æ³¨æ„äº‹é …ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¤œç´¢ï¼ˆè¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™ï¼‰
    patterns = [
        r'âš ï¸ æ³¨æ„äº‹é …\s*\n(.*?)(?=\n##|\n\*\*|$)',
        r'æ³¨æ„äº‹é …\s*\n(.*?)(?=\n##|\n\*\*|$)',
        r'## æ³¨æ„äº‹é …\s*\n(.*?)(?=\n##|\n\*\*|$)',
        r'âš ï¸\s*(.*?)(?=\n##|\n\*\*|$)',
        r'æ³¨æ„\s*\n(.*?)(?=\n##|\n\*\*|$)',
        r'## æ³¨æ„\s*\n(.*?)(?=\n##|\n\*\*|$)',
        r'å®‰å…¨ä¸Šã®æ³¨æ„äº‹é …\s*\n(.*?)(?=\n##|\n\*\*|$)',
        r'## å®‰å…¨ä¸Šã®æ³¨æ„äº‹é …\s*\n(.*?)(?=\n##|\n\*\*|$)'
    ]
    
    for i, pattern in enumerate(patterns):
        print(f"  ãƒ‘ã‚¿ãƒ¼ãƒ³ {i+1} ã‚’è©¦è¡Œä¸­...")
        warnings_match = re.search(pattern, content, re.DOTALL)
        if warnings_match:
            print(f"  âœ… ãƒ‘ã‚¿ãƒ¼ãƒ³ {i+1} ã§ãƒãƒƒãƒã—ã¾ã—ãŸ")
            warnings_section = warnings_match.group(1).strip()
            print(f"  æŠ½å‡ºã•ã‚ŒãŸã‚»ã‚¯ã‚·ãƒ§ãƒ³: {warnings_section[:200]}...")
            
            # æ³¨æ„äº‹é …æƒ…å ±ã‚’æ•´ç†
            warnings_lines = [line.strip() for line in warnings_section.split('\n') if line.strip()]
            print(f"  æ³¨æ„äº‹é …è¡Œæ•°: {len(warnings_lines)}")
            
            if warnings_lines:
                result = '\n'.join(warnings_lines)
                print(f"  âœ… æ³¨æ„äº‹é …æŠ½å‡ºæˆåŠŸ: {result[:100]}...")
                return result
            else:
                print(f"  âŒ æ³¨æ„äº‹é …è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        else:
            print(f"  âŒ ãƒ‘ã‚¿ãƒ¼ãƒ³ {i+1} ã§ãƒãƒƒãƒã—ã¾ã›ã‚“ã§ã—ãŸ")
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: âš ï¸ ãƒãƒ¼ã‚¯ã‚„ã€Œæ³¨æ„ã€ã‚’å«ã‚€è¡Œã‚’æ¤œç´¢
    print(f"  ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢ã‚’å®Ÿè¡Œ...")
    all_lines = content.split('\n')
    warnings_lines = []
    
    for line in all_lines:
        line = line.strip()
        # âš ï¸ ãƒãƒ¼ã‚¯ã‚’å«ã‚€è¡Œ
        if 'âš ï¸' in line or 'æ³¨æ„' in line or 'è­¦å‘Š' in line or 'å±é™º' in line:
            warnings_lines.append(line)
    
    if warnings_lines:
        print(f"  âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§ {len(warnings_lines)} è¡Œã®æ³¨æ„äº‹é …ã‚’ç™ºè¦‹")
        result = '\n'.join(warnings_lines)
        print(f"  çµæœ: {result[:100]}...")
        return result
    
    print(f"  âŒ æ³¨æ„äº‹é …ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    return ""

def get_fallback_suggestions(query: str) -> List[Dict]:
    """æ¤œç´¢çµæœãŒç©ºã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ææ¡ˆã‚’ç”Ÿæˆ"""
    suggestions = []
    query_lower = query.lower()
    
    # ä¸€èˆ¬çš„ãªä¿®ç†ã‚«ãƒ†ã‚´ãƒªã®ææ¡ˆ
    common_categories = {
        "ãƒãƒƒãƒ†ãƒªãƒ¼": {
            "title": "ğŸ”‹ ãƒãƒƒãƒ†ãƒªãƒ¼é–¢é€£ã®ä¿®ç†",
            "content": "ãƒãƒƒãƒ†ãƒªãƒ¼ã®å……é›»ä¸è‰¯ã€é›»åœ§ä¸è¶³ã€å§‹å‹•ä¸è‰¯ãªã©ã®å•é¡Œã«ã¤ã„ã¦",
            "keywords": ["ãƒãƒƒãƒ†ãƒªãƒ¼", "å……é›»", "é›»åœ§", "å§‹å‹•", "ã‚¨ãƒ³ã‚¸ãƒ³"]
        },
        "ã‚¨ã‚¢ã‚³ãƒ³": {
            "title": "â„ï¸ ã‚¨ã‚¢ã‚³ãƒ³ãƒ»ç©ºèª¿é–¢é€£ã®ä¿®ç†",
            "content": "ã‚¨ã‚¢ã‚³ãƒ³ã®å†·æˆ¿ãƒ»æš–æˆ¿ä¸è‰¯ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸…æƒã€æ¸©åº¦èª¿æ•´ãªã©ã®å•é¡Œã«ã¤ã„ã¦",
            "keywords": ["ã‚¨ã‚¢ã‚³ãƒ³", "å†·æˆ¿", "æš–æˆ¿", "ç©ºèª¿", "æ¸©åº¦"]
        },
        "ãƒˆã‚¤ãƒ¬": {
            "title": "ğŸš½ ãƒˆã‚¤ãƒ¬ãƒ»æ°´å›ã‚Šé–¢é€£ã®ä¿®ç†",
            "content": "ãƒˆã‚¤ãƒ¬ã®æ°´æ¼ã‚Œã€ãƒãƒ³ãƒ—ä¸è‰¯ã€æ’æ°´å•é¡Œãªã©ã®ä¿®ç†ã«ã¤ã„ã¦",
            "keywords": ["ãƒˆã‚¤ãƒ¬", "æ°´", "ãƒãƒ³ãƒ—", "æ’æ°´", "æ°´æ¼ã‚Œ"]
        },
        "é›»è£…ç³»": {
            "title": "âš¡ é›»è£…ç³»ãƒ»é›»æ°—é–¢é€£ã®ä¿®ç†",
            "content": "ãƒ’ãƒ¥ãƒ¼ã‚ºåˆ‡ã‚Œã€é…ç·šä¸è‰¯ã€ã‚¹ã‚¤ãƒƒãƒæ•…éšœãªã©ã®é›»æ°—ç³»çµ±ã®å•é¡Œã«ã¤ã„ã¦",
            "keywords": ["é›»è£…", "é›»æ°—", "ãƒ’ãƒ¥ãƒ¼ã‚º", "é…ç·š", "ã‚¹ã‚¤ãƒƒãƒ"]
        },
        "é›¨æ¼ã‚Š": {
            "title": "ğŸŒ§ï¸ é›¨æ¼ã‚Šãƒ»é˜²æ°´é–¢é€£ã®ä¿®ç†",
            "content": "å±‹æ ¹ã®é›¨æ¼ã‚Šã€ã‚·ãƒ¼ãƒªãƒ³ã‚°ä¸è‰¯ã€é˜²æ°´å‡¦ç†ãªã©ã®å•é¡Œã«ã¤ã„ã¦",
            "keywords": ["é›¨æ¼ã‚Š", "æ°´æ¼ã‚Œ", "ã‚·ãƒ¼ãƒªãƒ³ã‚°", "é˜²æ°´", "å±‹æ ¹"]
        },
        "ã‚¿ã‚¤ãƒ¤": {
            "title": "ğŸ› ã‚¿ã‚¤ãƒ¤ãƒ»ãƒ›ã‚¤ãƒ¼ãƒ«é–¢é€£ã®ä¿®ç†",
            "content": "ã‚¿ã‚¤ãƒ¤ã®ãƒ‘ãƒ³ã‚¯ã€ç©ºæ°—åœ§èª¿æ•´ã€ãƒ›ã‚¤ãƒ¼ãƒ«äº¤æ›ãªã©ã®å•é¡Œã«ã¤ã„ã¦",
            "keywords": ["ã‚¿ã‚¤ãƒ¤", "ãƒ›ã‚¤ãƒ¼ãƒ«", "ãƒ‘ãƒ³ã‚¯", "ç©ºæ°—åœ§", "äº¤æ›"]
        }
    }
    
    # ã‚¯ã‚¨ãƒªã«åŸºã¥ã„ã¦é–¢é€£ã‚«ãƒ†ã‚´ãƒªã‚’ææ¡ˆ
    for category, info in common_categories.items():
        if any(keyword in query_lower for keyword in info["keywords"]):
            suggestions.append({
                "title": info["title"],
                "category": "é–¢é€£ã‚«ãƒ†ã‚´ãƒª",
                "content": info["content"],
                "source": "suggestion",
                "relevance": "high"
            })
    
    # ä¸€èˆ¬çš„ãªä¿®ç†ã‚¢ãƒ‰ãƒã‚¤ã‚¹
    general_advice = {
        "title": "ğŸ”§ ä¸€èˆ¬çš„ãªä¿®ç†ã‚¢ãƒ‰ãƒã‚¤ã‚¹",
        "category": "ä¿®ç†ã‚¢ãƒ‰ãƒã‚¤ã‚¹",
        "content": """ã‚­ãƒ£ãƒ³ãƒ”ãƒ³ã‚°ã‚«ãƒ¼ã®ä¿®ç†ã§ã‚ˆãã‚ã‚‹å•é¡Œã¨å¯¾å‡¦æ³•ï¼š

1. **ãƒãƒƒãƒ†ãƒªãƒ¼é–¢é€£**
   - å……é›»ä¸è‰¯ï¼šå……é›»å™¨ã®ç¢ºèªã€ãƒãƒƒãƒ†ãƒªãƒ¼ç«¯å­ã®æ¸…æƒ
   - é›»åœ§ä¸è¶³ï¼šãƒãƒƒãƒ†ãƒªãƒ¼ã®äº¤æ›ã€å……é›»ã‚·ã‚¹ãƒ†ãƒ ã®ç‚¹æ¤œ

2. **ã‚¨ã‚¢ã‚³ãƒ³é–¢é€£**
   - å†·æˆ¿ä¸è‰¯ï¼šãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸…æƒã€å†·åª’ã®ç¢ºèª
   - æš–æˆ¿ä¸è‰¯ï¼šãƒ’ãƒ¼ã‚¿ãƒ¼ã®ç‚¹æ¤œã€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼äº¤æ›

3. **æ°´å›ã‚Šé–¢é€£**
   - æ°´æ¼ã‚Œï¼šãƒ‘ã‚¤ãƒ—æ¥ç¶šéƒ¨ã®ç¢ºèªã€ã‚·ãƒ¼ãƒªãƒ³ã‚°ã®è£œä¿®
   - ãƒãƒ³ãƒ—ä¸è‰¯ï¼šãƒãƒ³ãƒ—ã®ç‚¹æ¤œã€ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¸…æƒ

4. **é›»è£…ç³»é–¢é€£**
   - ãƒ’ãƒ¥ãƒ¼ã‚ºåˆ‡ã‚Œï¼šãƒ’ãƒ¥ãƒ¼ã‚ºãƒœãƒƒã‚¯ã‚¹ã®ç¢ºèªã€é©åˆ‡ãªå®¹é‡ã®ãƒ’ãƒ¥ãƒ¼ã‚ºä½¿ç”¨
   - é…ç·šä¸è‰¯ï¼šæ¥ç¶šéƒ¨ã®ç¢ºèªã€çµ¶ç¸ãƒ†ãƒ¼ãƒ—ã§ã®è£œä¿®""",
        "source": "general_advice",
        "relevance": "medium"
    }
    
    suggestions.append(general_advice)
    
    return suggestions

def format_repair_advice(rag_results: Dict, notion_cases: List[Dict], text_results: List[Dict], query: str) -> Dict:
    """ä¿®ç†ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    
    # çµ±åˆã•ã‚ŒãŸçµæœã‚’ä½œæˆ
    advice = {
        "query": query,
        "success": True,
        "results": []
    }
    
    # RAGçµæœã®å‡¦ç†
    if rag_results and rag_results.get("text_file_content"):
        rag_content = rag_results["text_file_content"]
        if rag_content.strip():
            # ä¿®ç†è²»ç”¨ã‚’æŠ½å‡º
            repair_costs = extract_repair_costs_from_content(rag_content)
            # ä¿®ç†æ‰‹é †ã‚’æŠ½å‡º
            repair_steps = extract_repair_steps_from_content(rag_content)
            # æ³¨æ„äº‹é …ã‚’æŠ½å‡º
            warnings = extract_warnings_from_content(rag_content)
            
            result_item = {
                "title": "ğŸ“„ RAGæ¤œç´¢çµæœ",
                "category": "RAGæ¤œç´¢",
                "content": rag_content[:1000] + "..." if len(rag_content) > 1000 else rag_content,
                "source": "rag_text",
                "relevance": "high"
            }
            
            # ä¿®ç†æ‰‹é †ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
            if repair_steps:
                result_item["repair_steps"] = repair_steps
                print(f"ğŸ”§ RAGçµæœã«ä¿®ç†æ‰‹é †ã‚’è¿½åŠ : {repair_steps[:100]}...")
            else:
                print("âš ï¸ RAGçµæœã‹ã‚‰ä¿®ç†æ‰‹é †ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            
            # æ³¨æ„äº‹é …ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
            if warnings:
                result_item["warnings"] = warnings
                print(f"âš ï¸ RAGçµæœã«æ³¨æ„äº‹é …ã‚’è¿½åŠ : {warnings[:100]}...")
            else:
                print("âš ï¸ RAGçµæœã‹ã‚‰æ³¨æ„äº‹é …ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            
            # ä¿®ç†è²»ç”¨ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
            if repair_costs:
                result_item["repair_costs"] = repair_costs
                result_item["costs"] = repair_costs  # å¾“æ¥ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚‚è¿½åŠ 
                print(f"ğŸ’° RAGçµæœã«ä¿®ç†è²»ç”¨ã‚’è¿½åŠ : {repair_costs[:100]}...")
            else:
                print("âš ï¸ RAGçµæœã‹ã‚‰ä¿®ç†è²»ç”¨ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            
            advice["results"].append(result_item)
    
    # Notionçµæœã®å‡¦ç†
    for case in notion_cases[:3]:  # æœ€å¤§3ä»¶
        if case.get("symptoms") or case.get("solutions"):
            advice["results"].append({
                "title": f"ğŸ”§ ä¿®ç†ã‚±ãƒ¼ã‚¹: {case.get('symptoms', 'ç—‡çŠ¶ä¸æ˜')[:50]}",
                "category": "ä¿®ç†ã‚±ãƒ¼ã‚¹",
                "content": f"ç—‡çŠ¶: {case.get('symptoms', '')}\nåŸå› : {case.get('causes', '')}\nè§£æ±ºç­–: {case.get('solutions', '')}",
                "costs": case.get("costs", ""),
                "tools": case.get("tools", ""),
                "parts": case.get("parts", ""),
                "source": "notion",
                "relevance": "high"
            })
    
    # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«çµæœã®å‡¦ç†
    for text_result in text_results[:3]:  # æœ€å¤§3ä»¶
        # ä¿®ç†è²»ç”¨ã‚’æŠ½å‡º
        repair_costs = extract_repair_costs_from_content(text_result["content"])
        # ä¿®ç†æ‰‹é †ã‚’æŠ½å‡º
        repair_steps = extract_repair_steps_from_content(text_result["content"])
        # æ³¨æ„äº‹é …ã‚’æŠ½å‡º
        warnings = extract_warnings_from_content(text_result["content"])
        
        result_item = {
            "title": f"ğŸ“‹ {text_result['filename']}",
            "category": "ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«",
            "content": text_result["content"][:800] + "..." if len(text_result["content"]) > 800 else text_result["content"],
            "source": "text_file",
            "relevance": text_result.get("relevance", "medium")
        }
        
        # ä¿®ç†æ‰‹é †ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        if repair_steps:
            result_item["repair_steps"] = repair_steps
            print(f"ğŸ”§ ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«çµæœã«ä¿®ç†æ‰‹é †ã‚’è¿½åŠ  ({text_result['filename']}): {repair_steps[:100]}...")
        else:
            print(f"âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«çµæœã‹ã‚‰ä¿®ç†æ‰‹é †ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ ({text_result['filename']})")
        
        # æ³¨æ„äº‹é …ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        if warnings:
            result_item["warnings"] = warnings
            print(f"âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«çµæœã«æ³¨æ„äº‹é …ã‚’è¿½åŠ  ({text_result['filename']}): {warnings[:100]}...")
        else:
            print(f"âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«çµæœã‹ã‚‰æ³¨æ„äº‹é …ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ ({text_result['filename']})")
        
        # ä¿®ç†è²»ç”¨ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        if repair_costs:
            result_item["repair_costs"] = repair_costs
            result_item["costs"] = repair_costs  # å¾“æ¥ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚‚è¿½åŠ 
            print(f"ğŸ’° ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«çµæœã«ä¿®ç†è²»ç”¨ã‚’è¿½åŠ  ({text_result['filename']}): {repair_costs[:100]}...")
        else:
            print(f"âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«çµæœã‹ã‚‰ä¿®ç†è²»ç”¨ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ ({text_result['filename']})")
        
        advice["results"].append(result_item)
    
    # ãƒ–ãƒ­ã‚°ãƒªãƒ³ã‚¯ã®è¿½åŠ 
    if rag_results and rag_results.get("blog_links"):
        blog_links = rag_results["blog_links"][:3]  # æœ€å¤§3ä»¶
        if blog_links:
            blog_content = "é–¢é€£ãƒ–ãƒ­ã‚°è¨˜äº‹:\n"
            for blog in blog_links:
                blog_content += f"â€¢ {blog['title']}: {blog['url']}\n"
            
            advice["results"].append({
                "title": "ğŸ”— é–¢é€£ãƒ–ãƒ­ã‚°è¨˜äº‹",
                "category": "ãƒ–ãƒ­ã‚°",
                "content": blog_content,
                "source": "blog",
                "relevance": "medium"
            })
    
    # çµæœãŒãªã„å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ææ¡ˆã‚’è¿½åŠ 
    if not advice["results"]:
        print("âš ï¸ æ¤œç´¢çµæœãŒç©ºã®ãŸã‚ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ææ¡ˆã‚’ç”Ÿæˆã—ã¾ã™")
        fallback_suggestions = get_fallback_suggestions(query)
        advice["results"] = fallback_suggestions
        advice["fallback"] = True  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨ãƒ•ãƒ©ã‚°
    
    return advice

@app.route('/')
def index():
    """ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸"""
    return render_template('repair_advice_center.html')

@app.route('/api/health')
def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return jsonify({
        "status": "healthy",
        "rag_available": RAG_AVAILABLE and rag_db is not None,
        "notion_available": NOTION_AVAILABLE and notion_client is not None
    })

@app.route('/api/search', methods=['POST'])
def search_repair_advice():
    """ä¿®ç†ã‚¢ãƒ‰ãƒã‚¤ã‚¹æ¤œç´¢API"""
    try:
        data = request.get_json()
        query = data.get('query', '').strip()
        
        if not query:
            return jsonify({
                "success": False,
                "error": "æ¤œç´¢ã‚¯ã‚¨ãƒªãŒç©ºã§ã™"
            })
        
        print(f"ğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}")
        
        # RAGã‚·ã‚¹ãƒ†ãƒ ã§ã®æ¤œç´¢
        rag_results = None
        if rag_db:
            try:
                rag_results = enhanced_rag_retrieve(query, rag_db, max_results=5)
                print(f"âœ… RAGæ¤œç´¢å®Œäº†: {len(rag_results.get('text_file_content', ''))} æ–‡å­—")
            except Exception as e:
                print(f"âŒ RAGæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        
        # Notionã§ã®æ¤œç´¢
        notion_cases = []
        if notion_client:
            try:
                notion_cases = search_notion_repair_cases(query)
                print(f"âœ… Notionæ¤œç´¢å®Œäº†: {len(notion_cases)} ä»¶")
            except Exception as e:
                print(f"âŒ Notionæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§ã®æ¤œç´¢
        text_results = []
        try:
            text_results = search_text_files(query)
            print(f"âœ… ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢å®Œäº†: {len(text_results)} ä»¶")
        except Exception as e:
            print(f"âŒ ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        
        # çµæœã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        advice = format_repair_advice(rag_results, notion_cases, text_results, query)
        
        return jsonify(advice)
        
    except Exception as e:
        print(f"âŒ API ã‚¨ãƒ©ãƒ¼: {e}")
        return jsonify({
            "success": False,
            "error": f"æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        })

@app.route('/api/notion/status')
def notion_status():
    """Notionæ¥ç¶šçŠ¶æ³ã®ç¢ºèª"""
    if not NOTION_AVAILABLE:
        return jsonify({
            "available": False,
            "error": "Notionã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“"
        })
    
    if not notion_client:
        return jsonify({
            "available": False,
            "error": "Notionã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
        })
    
    try:
        # ç°¡å˜ãªæ¥ç¶šãƒ†ã‚¹ãƒˆ
        case_db_id = os.getenv("CASE_DB_ID")
        if case_db_id:
            response = notion_client.databases.query(database_id=case_db_id, page_size=1)
            return jsonify({
                "available": True,
                "case_db_connected": True,
                "case_count": response.get("results", [])
            })
        else:
            return jsonify({
                "available": True,
                "error": "CASE_DB_IDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            })
    except Exception as e:
        return jsonify({
            "available": False,
            "error": f"Notionæ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}"
        })

if __name__ == '__main__':
    print("ğŸš€ ä¿®ç†ã‚¢ãƒ‰ãƒã‚¤ã‚¹APIã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ä¸­...")
    
    # ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    initialize_rag_system()
    initialize_notion_client()
    
    # ã‚µãƒ¼ãƒãƒ¼èµ·å‹•
    port = int(os.getenv('PORT', 5000))
    debug = os.getenv('DEBUG', 'False').lower() == 'true'
    
    print(f"ğŸŒ ã‚µãƒ¼ãƒãƒ¼èµ·å‹•: http://localhost:{port}")
    print(f"ğŸ“Š RAGã‚·ã‚¹ãƒ†ãƒ : {'âœ… åˆ©ç”¨å¯èƒ½' if rag_db else 'âŒ åˆ©ç”¨ä¸å¯'}")
    print(f"ğŸ“‹ Notion: {'âœ… åˆ©ç”¨å¯èƒ½' if notion_client else 'âŒ åˆ©ç”¨ä¸å¯'}")
    
    app.run(host='0.0.0.0', port=port, debug=debug)
