#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ‰ã‚¢æ¤œç´¢ã®ãƒ‡ãƒãƒƒã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import os
import re
import glob

def analyze_query(query):
    """ã‚¯ã‚¨ãƒªã‚’è§£æã—ã¦æ¤œç´¢æˆ¦ç•¥ã‚’æ±ºå®š"""
    query_lower = query.lower()
    
    # ã‚¯ã‚¨ãƒªã®ç¨®é¡ã‚’åˆ¤å®š
    query_type = {
        'is_specific_problem': False,  # å…·ä½“çš„ãªå•é¡Œ
        'is_general_category': False,  # ä¸€èˆ¬çš„ãªã‚«ãƒ†ã‚´ãƒª
        'has_action_verb': False,     # å‹•ä½œå‹•è©ã‚’å«ã‚€
        'has_symptom': False,         # ç—‡çŠ¶ã‚’å«ã‚€
        'main_keywords': [],
        'context_keywords': [],
        'priority_score': 0
    }
    
    # ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æŠ½å‡º
    main_keywords = []
    if 'ãƒ‰ã‚¢' in query_lower or 'door' in query_lower:
        main_keywords.append('ãƒ‰ã‚¢')
    if 'çª“' in query_lower or 'window' in query_lower:
        main_keywords.append('çª“')
    if 'é–‹é–‰' in query_lower or 'é–‹ã‘é–‰ã‚' in query_lower:
        main_keywords.append('é–‹é–‰')
    if 'ä¸å…·åˆ' in query_lower or 'æ•…éšœ' in query_lower:
        main_keywords.append('ä¸å…·åˆ')
    
    query_type['main_keywords'] = main_keywords
    
    return query_type

def search_repair_advice_debug(query):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¿®ç†ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æ¤œç´¢ï¼ˆãƒ‡ãƒãƒƒã‚°ç‰ˆï¼‰"""
    try:
        # ãƒ‰ã‚¢é–¢é€£ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
        text_files = [
            ("ãƒ‰ã‚¢ãƒ»çª“", "ãƒ‰ã‚¢ãƒ»çª“ã®é–‹é–‰ä¸è‰¯.txt"),
        ]
        
        results = []
        query_lower = query.lower()
        
        print(f"ğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}")
        print(f"ğŸ” ã‚¯ã‚¨ãƒªè§£æ: {analyze_query(query)}")
        
        # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        for category, filename in text_files:
            try:
                if not os.path.exists(filename):
                    print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filename}")
                    continue
                    
                print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {filename}")
                with open(filename, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                print(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {len(content)} æ–‡å­—")
                
                # ã‚¯ã‚¨ãƒªè§£æçµæœã‚’å–å¾—
                query_analysis = analyze_query(query_lower)
                
                # é«˜åº¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
                matches = []
                query_words = [word.strip() for word in query_lower.split() if len(word.strip()) > 1]
                
                print(f"ğŸ” æ¤œç´¢å˜èª: {query_words}")
                print(f"ğŸ” ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {query_analysis['main_keywords']}")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã®é–¢é€£æ€§ã‚’äº‹å‰ãƒã‚§ãƒƒã‚¯
                file_relevance = 0
                filename_lower = filename.lower()
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åã¨ã®é–¢é€£æ€§ãƒã‚§ãƒƒã‚¯
                if any(keyword in filename_lower for keyword in query_analysis['main_keywords']):
                    file_relevance += 30
                    print(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«åãƒãƒƒãƒ: +30ç‚¹")
                
                # ã‚«ãƒ†ã‚´ãƒªã¨ã®é–¢é€£æ€§ãƒã‚§ãƒƒã‚¯
                if any(keyword in category.lower() for keyword in query_analysis['main_keywords']):
                    file_relevance += 25
                    print(f"âœ… ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ: +25ç‚¹")
                
                print(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«é–¢é€£æ€§ã‚¹ã‚³ã‚¢: {file_relevance}")
                
                # ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å®Œå…¨ä¸€è‡´ï¼ˆé«˜å„ªå…ˆåº¦ï¼‰
                for keyword in query_analysis['main_keywords']:
                    if keyword in content.lower():
                        count = content.lower().count(keyword)
                        matches.append(('main_keyword', keyword, 40, count))
                        print(f"âœ… ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ: {keyword} ({count}å›) +{40*count}ç‚¹")
                
                # å®Œå…¨ä¸€è‡´ï¼ˆæœ€é«˜å„ªå…ˆåº¦ï¼‰
                if query_lower in content.lower():
                    count = content.lower().count(query_lower)
                    matches.append(('exact', query_lower, 60, count))
                    print(f"âœ… å®Œå…¨ä¸€è‡´: {query_lower} ({count}å›) +{60*count}ç‚¹")
                
                # éƒ¨åˆ†ä¸€è‡´
                for word in query_words:
                    if len(word) >= 3 and word in content.lower():
                        count = content.lower().count(word)
                        matches.append(('partial', word, 20, count))
                        print(f"âœ… éƒ¨åˆ†ä¸€è‡´: {word} ({count}å›) +{20*count}ç‚¹")
                
                if matches:
                    # é–¢é€£åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
                    score = file_relevance
                    
                    for match_type, keyword, weight, count in matches:
                        score += count * weight
                    
                    print(f"ğŸ“Š æœ€çµ‚ã‚¹ã‚³ã‚¢: {score}")
                    
                    # ä¿®ç†è²»ç”¨ã¨ä»£æ›¿å“æƒ…å ±ã‚’æŠ½å‡º
                    costs = []
                    alternatives = []
                    urls = []
                    
                    # è²»ç”¨æŠ½å‡º
                    cost_patterns = [
                        r'(\d+[,ï¼Œ]\d+å††)',
                        r'(\d+å††)',
                        r'(\d+ä¸‡å††)',
                        r'(\d+åƒå††)',
                    ]
                    for pattern in cost_patterns:
                        cost_matches = re.findall(pattern, content)
                        costs.extend(cost_matches)
                    costs = list(set(costs))[:5]
                    
                    print(f"ğŸ’° æŠ½å‡ºã•ã‚ŒãŸè²»ç”¨: {costs}")
                    
                    results.append({
                        'title': f"{category}ä¿®ç†ã‚¢ãƒ‰ãƒã‚¤ã‚¹",
                        'category': category,
                        'filename': filename,
                        'content': content[:500] + "..." if len(content) > 500 else content,
                        'costs': costs,
                        'alternatives': alternatives,
                        'urls': urls,
                        'score': score
                    })
                    
                    print(f"âœ… çµæœã‚’è¿½åŠ : {category}")
                else:
                    print(f"âŒ ãƒãƒƒãƒãªã—: {category}")
                    
            except Exception as e:
                print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ« {filename} ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
                continue
        
        # ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
        results.sort(key=lambda x: x['score'], reverse=True)
        
        print(f"ğŸ“Š æœ€çµ‚çµæœæ•°: {len(results)}")
        for i, result in enumerate(results):
            print(f"  {i+1}. {result['title']} (ã‚¹ã‚³ã‚¢: {result['score']})")
        
        return results
        
    except Exception as e:
        print(f"âŒ æ¤œç´¢å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    query = "ãƒ‰ã‚¢ã®é–‹ã‘é–‰ã‚ã®ä¸å…·åˆ"
    results = search_repair_advice_debug(query)
    
    print(f"\nğŸ¯ æ¤œç´¢çµæœ:")
    for result in results:
        print(f"ğŸ“„ {result['title']}")
        print(f"   ã‚¹ã‚³ã‚¢: {result['score']}")
        print(f"   è²»ç”¨: {result['costs']}")
        print(f"   å†…å®¹: {result['content'][:100]}...")
        print()
